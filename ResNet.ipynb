{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. import what u need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch     \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_curve,precision_recall_curve,average_precision_score,auc\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,confusion_matrix,matthews_corrcoef,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import dataClass as MyDataClass\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "#加载数据集并转换成torch.Tensor\n",
    "# 训练集\n",
    "tensor = np.load(\"./final-project1-j1/train_data.npy\")\n",
    "df = pd.read_csv(\"./final-project1-j1/train_data.csv\")\n",
    "label = list(df[\"label\"])\n",
    "# 数据reshape成(N,1,24,24)，这里加入了随机裁剪\n",
    "train_tensor = []\n",
    "for i in range(len(tensor)):\n",
    "    train_tensor.append([])\n",
    "    train_tensor[i].append([])    \n",
    "    h = int(random.random() * 4)\n",
    "    w = int(random.random() * 4)\n",
    "    for j in range(24):\n",
    "        train_tensor[i][0].append(tensor[i][(j+h)*28+w:(j+h)*28+w+24])\n",
    "train_tensor = torch.Tensor(train_tensor)\n",
    "train_dataset = MyDataClass.mydataset(train_tensor, label)\n",
    "# 验证集\n",
    "tensor = np.load(\"./final-project1-j1/development_data.npy\")\n",
    "df = pd.read_csv(\"./final-project1-j1/development_data.csv\")\n",
    "label = list(df[\"label\"])\n",
    "development_tensor = []\n",
    "for i in range(len(tensor)):\n",
    "    development_tensor.append([])\n",
    "    development_tensor[i].append([])    \n",
    "    h = int(random.random() * 4)\n",
    "    w = int(random.random() * 4)\n",
    "    for j in range(24):\n",
    "        development_tensor[i][0].append(tensor[i][(j+h)*28+w:(j+h)*28+w+24])\n",
    "development_tensor = torch.Tensor(development_tensor)\n",
    "development_dataset = MyDataClass.mydataset(development_tensor, label)\n",
    "# 测试集\n",
    "tensor = np.load(\"./final-project1-j1/test.npy\")\n",
    "test_tensor = []\n",
    "for i in range(len(tensor)):\n",
    "    test_tensor.append([])\n",
    "    test_tensor[i].append([])    \n",
    "    h = int(random.random() * 4)\n",
    "    w = int(random.random() * 4)\n",
    "    for j in range(24):\n",
    "        test_tensor[i][0].append(tensor[i][(j+h)*28+w:(j+h)*28+w+24])\n",
    "test_dataset = torch.Tensor(test_tensor)\n",
    "#加载小批次数据，即将数据集中的data分成每组batch_size的小块，shuffle指定是否随机读取\n",
    "train_loader = Data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "development_loader = Data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # 经过处理后的x要与x的维度相同(尺寸和深度)\n",
    "        # 如果不相同，需要添加卷积+BN来变换为同一维度\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(Model, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(ResBlock,[2,2,2,2])#.cuda() #实例化卷积层\n",
    "model.load_state_dict(torch.load(\"ResNetModule13_0.01_cutdata.pt\"))\n",
    "loss = nn.CrossEntropyLoss() #损失函数选择，交叉熵函数\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 0\n",
      "lose: 0.014292142104447993\n",
      "accuracy: 0.9956042199488491\n",
      "echo: 1\n",
      "lose: 0.022822222474035318\n",
      "accuracy: 0.9921675191815856\n",
      "echo: 2\n",
      "lose: 0.02171651669028934\n",
      "accuracy: 0.9927269820971867\n",
      "echo: 3\n",
      "lose: 0.01570033660988216\n",
      "accuracy: 0.9948849104859335\n",
      "echo: 4\n",
      "lose: 0.01959516842792387\n",
      "accuracy: 0.9932464833759591\n",
      "echo: 5\n",
      "lose: 0.015478323368356228\n",
      "accuracy: 0.9948049872122762\n",
      "echo: 6\n",
      "lose: 0.014785873982854846\n",
      "accuracy: 0.99528452685422\n",
      "echo: 7\n",
      "lose: 0.016465657324449386\n",
      "accuracy: 0.9944053708439897\n",
      "echo: 8\n",
      "lose: 0.024005130871592905\n",
      "accuracy: 0.9914881713554987\n",
      "echo: 9\n",
      "lose: 0.018023423264147197\n",
      "accuracy: 0.9933264066496164\n"
     ]
    }
   ],
   "source": [
    "# 88\n",
    "losses = [] \n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "num_epochs = 10\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10,eta_min=4e-08)\n",
    "for echo in range(num_epochs):\n",
    "    train_loss = 0   #定义训练损失\n",
    "    train_acc = 0    #定义训练准确度\n",
    "    model.train()    #将网络转化为训练模式\n",
    "    # data reload，每个epoch重新裁剪\n",
    "    tensor = np.load(\"./final-project1-j1/train_data.npy\")\n",
    "    df = pd.read_csv(\"./final-project1-j1/train_data.csv\")\n",
    "    label = list(df[\"label\"])\n",
    "    train_tensor = []\n",
    "    for i in range(len(tensor)):\n",
    "        train_tensor.append([])\n",
    "        train_tensor[i].append([])    \n",
    "        h = int(random.random() * 4)\n",
    "        w = int(random.random() * 4)\n",
    "        for j in range(24):\n",
    "            train_tensor[i][0].append(tensor[i][(j+h)*28+w:(j+h)*28+w+24])\n",
    "    train_tensor = torch.Tensor(train_tensor)\n",
    "    train_dataset = MyDataClass.mydataset(train_tensor, label)\n",
    "    train_loader = Data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "    for i,(X,label) in enumerate(train_loader):     #使用枚举函数遍历train_loader\n",
    "        #X = X.view(-1,784)       #X:[64,1,28,28] -> [64,784]将X向量展平\n",
    "        X = Variable(X)#.cuda()          #包装tensor用于自动求梯度\n",
    "        label = Variable(label)#.cuda()\n",
    "        out = model(X)           #正向传播\n",
    "        lossvalue = loss(out,label)         #求损失值\n",
    "        optimizer.zero_grad()       #优化器梯度归零\n",
    "        lossvalue.backward()    #反向转播，刷新梯度值\n",
    "        optimizer.step()        #优化器运行一步，注意optimizer搜集的是model的参数\n",
    "        scheduler.step()\n",
    "        \n",
    "        #计算损失\n",
    "        train_loss += float(lossvalue)      \n",
    "        #计算精确度\n",
    "        _,pred = out.max(1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        acc = int(num_correct) / X.shape[0]\n",
    "        train_acc += acc\n",
    "\n",
    "    losses.append(train_loss / len(train_loader))\n",
    "    acces.append(train_acc / len(train_loader))\n",
    "    print(\"echo:\"+' ' +str(echo))\n",
    "    print(\"lose:\" + ' ' + str(train_loss / len(train_loader)))\n",
    "    print(\"accuracy:\" + ' '+str(train_acc / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'ResNetModule88_0.01_cutdata.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lose: 0.009708679669534027\n",
      "accuracy: 0.9973225703324808\n"
     ]
    }
   ],
   "source": [
    "model.eval() #模型转化为评估模式\n",
    "development_acc = 0\n",
    "development_loss = 0\n",
    "for X,label in development_loader:\n",
    "    #X = X.view(-1,784)\n",
    "    X = Variable(X)#.cuda()\n",
    "    label = Variable(label)#.cuda()\n",
    "    developmentout = model(X)\n",
    "    developmentloss = loss(developmentout,label)\n",
    "    #计算损失\n",
    "    development_loss += float(developmentloss)  \n",
    "\n",
    "    _, pred = developmentout.max(1)\n",
    "    num_correct = (pred == label).sum()\n",
    "    acc = int(num_correct) / X.shape[0]\n",
    "    development_acc += acc\n",
    "print(\"lose:\" + ' ' + str(development_loss / len(development_loader)))\n",
    "print(\"accuracy:\" + ' '+str(development_acc / len(development_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_label = []\n",
    "model.eval() #模型转化为评估模式\n",
    "tensor = np.load(\"./final-project1-j1/test.npy\")\n",
    "for X in test_loader:\n",
    "    X = Variable(X)#.cuda()\n",
    "    testout = model(X)\n",
    "\n",
    "    _, pred = testout.max(1)\n",
    "    test_pred_label += list(pred)\n",
    "# 写入csv文件\n",
    "for i, x in enumerate(test_pred_label):\n",
    "    test_pred_label[i] = int(x)\n",
    "data = {'image_id':list(range(5000)), 'label':test_pred_label}\n",
    "df = pd.DataFrame(data,columns=['image_id','label'])\n",
    "df.to_csv(r'submit_ResNet88_cutdata_lr0.01_randomcut_CosineDecay.csv',encoding='gbk',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
