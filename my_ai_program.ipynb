{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. import what u need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch     \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_curve,precision_recall_curve,average_precision_score,auc\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,confusion_matrix,matthews_corrcoef,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import dataClass as MyDataClass\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "#加载数据集并转换成torch.Tensor\n",
    "tensor = np.load(\"./final-project1-j1/train.npy\")\n",
    "df = pd.read_csv(\"./final-project1-j1/train.csv\")\n",
    "label = list(df[\"label\"])\n",
    "train_tensor = []\n",
    "for i in range(len(tensor)):\n",
    "    train_tensor.append([])\n",
    "    train_tensor[i].append([])\n",
    "    for j in range(28):\n",
    "        train_tensor[i][0].append(tensor[i][j*28:(j+1)*28])\n",
    "train_tensor = torch.Tensor(train_tensor)\n",
    "\n",
    "train_dataset = MyDataClass.mydataset(train_tensor, label)\n",
    "train_dataset, development_dataset = torch.utils.data.random_split(train_dataset, [25000, 5000])\n",
    "tensor = np.load(\"./final-project1-j1/test.npy\")\n",
    "test_tensor = []\n",
    "for i in range(len(tensor)):\n",
    "    test_tensor.append([])\n",
    "    test_tensor[i].append([])\n",
    "    for j in range(28):\n",
    "        test_tensor[i][0].append(tensor[i][j*28:(j+1)*28])\n",
    "test_dataset = torch.Tensor(test_tensor)\n",
    "#加载小批次数据，即将数据集中的data分成每组batch_size的小块，shuffle指定是否随机读取\n",
    "train_loader = Data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "development_loader = Data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义网络模型亦即Net 这里定义一个简单的全连接层784->10\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 64, kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 256, kernel_size=3,padding=1)\n",
    "        self.linear1 = nn.Linear(256,128)\n",
    "        self.linear2 = nn.Linear(128,128)\n",
    "        self.linear3 = nn.Linear(128,10)        \n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(F.max_pool2d(self.conv1(X),2,stride=2))\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.relu(F.max_pool2d(self.conv3(X),2,stride=2))\n",
    "        X = F.relu(self.conv4(X))\n",
    "        X = F.relu(F.max_pool2d(self.conv5(X),2))\n",
    "        X = F.relu(F.avg_pool2d(self.conv6(X),2))\n",
    "        X = X.view(-1, 256)\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.dropout(X, training=self.training)\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = F.dropout(X, training=self.training)\n",
    "        return self.linear3(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model()#.cuda() #实例化卷积层\n",
    "loss = nn.CrossEntropyLoss() #损失函数选择，交叉熵函数\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo: 0\n",
      "lose: 1.8190904720055172\n",
      "accuracy: 0.2897218670076726\n"
     ]
    }
   ],
   "source": [
    "losses = [] \n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "num_epochs = 1\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5,eta_min=4e-08)\n",
    "for echo in range(num_epochs):\n",
    "    train_loss = 0   #定义训练损失\n",
    "    train_acc = 0    #定义训练准确度\n",
    "    model.train()    #将网络转化为训练模式\n",
    "    for i,(X,label) in enumerate(train_loader):     #使用枚举函数遍历train_loader\n",
    "        #X = X.view(-1,784)       #X:[64,1,28,28] -> [64,784]将X向量展平\n",
    "        X = Variable(X)#.cuda()          #包装tensor用于自动求梯度\n",
    "        label = Variable(label)#.cuda()\n",
    "        out = model(X)           #正向传播\n",
    "        lossvalue = loss(out,label)         #求损失值\n",
    "        optimizer.zero_grad()       #优化器梯度归零\n",
    "        lossvalue.backward()    #反向转播，刷新梯度值\n",
    "        optimizer.step()        #优化器运行一步，注意optimizer搜集的是model的参数\n",
    "        scheduler.step()\n",
    "        \n",
    "        #计算损失\n",
    "        train_loss += float(lossvalue)      \n",
    "        #计算精确度\n",
    "        _,pred = out.max(1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        acc = int(num_correct) / X.shape[0]\n",
    "        train_acc += acc\n",
    "\n",
    "    losses.append(train_loss / len(train_loader))\n",
    "    acces.append(train_acc / len(train_loader))\n",
    "    print(\"echo:\"+' ' +str(echo))\n",
    "    print(\"lose:\" + ' ' + str(train_loss / len(train_loader)))\n",
    "    print(\"accuracy:\" + ' '+str(train_acc / len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8560182225063938\n"
     ]
    }
   ],
   "source": [
    "model.eval() #模型转化为评估模式\n",
    "development_acc = 0\n",
    "for X,label in development_loader:\n",
    "    X = Variable(X)#.cuda()\n",
    "    label = Variable(label)#.cuda()\n",
    "    developmentout = model(X)\n",
    "    developmentloss = loss(developmentout,label)\n",
    "\n",
    "    _, pred = developmentout.max(1)\n",
    "    num_correct = (pred == label).sum()\n",
    "    acc = int(num_correct) / X.shape[0]\n",
    "    development_acc += acc\n",
    "print(\"accuracy:\" + ' '+str(development_acc / len(development_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'mymodule.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "test_pred_label = []\n",
    "model.eval() #模型转化为评估模式\n",
    "tensor = np.load(\"./final-project1-j1/test.npy\")\n",
    "print(len(tensor))\n",
    "print(len(test_dataset))\n",
    "for X in test_loader:\n",
    "    X = Variable(X)#.cuda()\n",
    "    testout = model(X)\n",
    "\n",
    "    _, pred = testout.max(1)\n",
    "    test_pred_label += list(pred)\n",
    "for i, x in enumerate(test_pred_label):\n",
    "    test_pred_label[i] = int(x)\n",
    "data = {'image_id':list(range(5000)), 'label':test_pred_label}\n",
    "df = pd.DataFrame(data,columns=['image_id','label'])\n",
    "df.to_csv(r'submit.csv',encoding='gbk',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
